{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed training with Amazon SageMaker built-in algorithm XGBoost \n",
    "\n",
    "This notebook shows usage of SageMaker Managed Spot infrastructure for XGBoost training. Below we show how Spot instances can be used for the 'algorithm mode' and 'script mode' training methods with the XGBoost container. \n",
    "\n",
    "[Managed Spot Training](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html) uses Amazon EC2 Spot instance to run training jobs instead of on-demand instances. You can specify which training jobs use spot instances and a stopping condition that specifies how long Amazon SageMaker waits for a job to run using Amazon EC2 Spot instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was tested in Amazon SageMaker Studio on a ml.t3.medium instance with Python 3 (Data Science) kernel.\n",
    "\n",
    "In this notebook we will perform XGBoost training as described [here](). See the original notebook for more details on the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup variables and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.7/site-packages (2.107.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.112.2.tar.gz (579 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.2/579.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (21.4.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.24.62)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.21.6)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.20.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (4.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.3.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.9)\n",
      "Collecting schema\n",
      "  Using cached schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.62 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.62)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.13)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (1.7.6.5)\n",
      "Requirement already satisfied: pox>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.1)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.62->boto3<2.0,>=1.20.21->sagemaker) (1.26.12)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.112.2-py2.py3-none-any.whl size=796129 sha256=d4ce37abe0c458d35c13e4b445d2c80b86ffe5b6a244f0aeb19ebd3ae05ccb4a\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/2a/d8/0db78f00aee63d4fddc2c64edcb1e761ef8e1a502137dcbaeb\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: schema, sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.107.0\n",
      "    Uninstalling sagemaker-2.107.0:\n",
      "      Successfully uninstalled sagemaker-2.107.0\n",
      "Successfully installed sagemaker-2.112.2 schema-0.7.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n",
      "CPU times: user 136 ms, sys: 3.09 ms, total: 139 ms\n",
      "Wall time: 531 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "### update below values appropriately ###\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/xgboost-dist-builtin'\n",
    "\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 358 ms, sys: 53.7 ms, total: 411 ms\n",
      "Wall time: 1.59 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0    2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1    2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2    0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3    2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4    1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera weight  Shell weight  Rings  \n",
       "0          0.1010         0.150     15  \n",
       "1          0.0485         0.070      7  \n",
       "2          0.1415         0.210      9  \n",
       "3          0.1140         0.155     10  \n",
       "4          0.0395         0.055      7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pyarrow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "# Download the dataset and load into a pandas dataframe\n",
    "FILE_NAME = 'abalone.csv'\n",
    "s3.download_file(\"sagemaker-sample-files\", f\"datasets/tabular/uci_abalone/abalone.csv\", FILE_NAME)\n",
    "\n",
    "feature_names=['Sex', \n",
    "               'Length', \n",
    "               'Diameter', \n",
    "               'Height', \n",
    "               'Whole weight', \n",
    "               'Shucked weight', \n",
    "               'Viscera weight', \n",
    "               'Shell weight', \n",
    "               'Rings']\n",
    "\n",
    "data = pd.read_csv(FILE_NAME, \n",
    "                   header=None, \n",
    "                   names=feature_names)\n",
    "data[\"Sex\"] = data[\"Sex\"].astype(\"category\").cat.codes\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rings</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rings  Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0     15    2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1      7    2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2      9    0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3     10    2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4      7    1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "\n",
       "   Viscera weight  Shell weight  \n",
       "0          0.1010         0.150  \n",
       "1          0.0485         0.070  \n",
       "2          0.1415         0.210  \n",
       "3          0.1140         0.155  \n",
       "4          0.0395         0.055  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SageMaker XGBoost has the convention of label in the first column\n",
    "data = data[feature_names[-1:] + feature_names[:-1]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the downloaded data into train/test dataframes\n",
    "train, validation = np.split(data.sample(frac=1), [int(.8*len(data))])\n",
    "train_0, train_1 = np.split(train.sample(frac=1), [int(.5*len(train))])\n",
    "\n",
    "# requires PyArrow installed\n",
    "train_0.to_csv('abalone_train_0.csv', index=False, header=False)\n",
    "train_1.to_csv('abalone_train_1.csv', index=False, header=False)\n",
    "validation.to_csv('abalone_validation.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 0 ns, total: 103 ms\n",
      "Wall time: 387 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-240487350066/sagemaker/xgboost-dist-builtin/validation/abalone_validation.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sagemaker.Session().upload_data('abalone_train_0.csv', \n",
    "                                bucket=bucket, \n",
    "                                key_prefix=prefix+'/'+'train')\n",
    "\n",
    "sagemaker.Session().upload_data('abalone_train_1.csv', \n",
    "                                bucket=bucket, \n",
    "                                key_prefix=prefix+'/'+'train')\n",
    "\n",
    "sagemaker.Session().upload_data('abalone_validation.csv', \n",
    "                                bucket=bucket, \n",
    "                                key_prefix=prefix+'/'+'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the latest XGBoost container\n",
    "We obtain the new container by specifying the framework version (1.5-1). This version specifies the upstream XGBoost framework version (1.5) and an additional SageMaker version (1). If you have an existing XGBoost workflow based on the previous (1.0-1, 1.2-2 or 1.3-1) container, this would be the only change necessary to get the same workflow working with the new container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.5-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the XGBoost model\n",
    "\n",
    "After setting training parameters, we kick off training, and poll for status until training is completed, which in this example, takes few minutes.\n",
    "\n",
    "To run our training script on SageMaker, we construct a sagemaker.xgboost.estimator.XGBoost estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __hyperparameters__: A dictionary passed to the train function as hyperparameters.\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training. __Note__: This particular mode does not currently support training on GPU instance types.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"2\",\n",
    "}\n",
    "\n",
    "instance_type = \"ml.m5.2xlarge\"\n",
    "instance_count = 2\n",
    "output_path = \"s3://{}/{}/{}/output\".format(bucket, prefix, \"abalone-xgb\")\n",
    "content_type = \"csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Spot instances are used, the training job can be interrupted, causing it to take longer to start or finish. If a training job is interrupted, a checkpointed snapshot can be used to resume from a previously saved point and can save training time (and cost).\n",
    "\n",
    "To enable checkpointing for Managed Spot Training using SageMaker XGBoost we need to configure three things: \n",
    "\n",
    "1. Enable the `train_use_spot_instances` constructor arg - a simple self-explanatory boolean. \n",
    "\n",
    "2. Set the `train_max_wait constructor` arg - this is an int arg representing the amount of time you are willing to wait for Spot infrastructure to become available. Some instance types are harder to get at Spot prices and you may have to wait longer. You are not charged for time spent waiting for Spot infrastructure to become available, you're only charged for actual compute time spent once Spot instances have been successfully procured. \n",
    "\n",
    "3. Setup a `checkpoint_s3_uri` constructor arg - this arg will tell SageMaker an S3 location where to save checkpoints. While not strictly necessary, checkpointing is highly recommended for Manage Spot Training jobs due to the fact that Spot instances can be interrupted with short notice and using checkpoints to resume from the last interruption ensures you don't lose any progress made before the interruption.\n",
    "\n",
    "Feel free to toggle the `train_use_spot_instances` variable to see the effect of running the same job using regular (a.k.a. \"On Demand\") infrastructure.\n",
    "\n",
    "Note that `train_max_wait` can be set if and only if `train_use_spot_instances` is enabled and must be greater than or equal to `train_max_run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-xgboost-builtin-2022-10-13-01-15-07\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "job_name = \"DEMO-xgboost-builtin-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "# use_spot_instances = True\n",
    "# max_run = 3600\n",
    "# max_wait = 7200 if use_spot_instances else None\n",
    "# checkpoint_s3_uri = (\n",
    "#     \"s3://{}/{}/checkpoints/{}\".format(bucket, prefix, job_name) if use_spot_instances else None\n",
    "# )\n",
    "# print(\"Checkpoint path:\", checkpoint_s3_uri)\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_count=instance_count,\n",
    "    instance_type=instance_type,\n",
    "    volume_size=5,  # 5 GB\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    # use_spot_instances=use_spot_instances,\n",
    "    # max_run=max_run,\n",
    "    # max_wait=max_wait,\n",
    "    # checkpoint_s3_uri=checkpoint_s3_uri,\n",
    ")\n",
    "\n",
    "train_input = TrainingInput(\n",
    "    \"s3://{}/{}/{}/\".format(bucket, prefix, \"train\"), \n",
    "    distribution='ShardedByS3Key', \n",
    "    content_type=content_type)\n",
    "\n",
    "validation_input = TrainingInput(\n",
    "    \"s3://{}/{}/{}/\".format(bucket, prefix, \"validation\"), \n",
    "    distribution='FullyReplicated', \n",
    "    content_type=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-13 01:15:35 Starting - Starting the training job...\n",
      "2022-10-13 01:16:00 Starting - Preparing the instances for trainingProfilerReport-1665623735: InProgress\n",
      "......\n",
      "2022-10-13 01:17:01 Downloading - Downloading input data...\n",
      "2022-10-13 01:17:21 Training - Downloading the training image.....\u001b[35m[2022-10-13 01:18:10.279 ip-10-0-182-51.us-west-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\u001b[0m\n",
      "\u001b[35mReturning the value itself\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:10:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:13:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[35m[01:18:13] task NULL got new rank 1\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:13:INFO] Failed to connect to RabitTracker on attempt 0\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:13:INFO] Sleeping for 3 sec before retrying\u001b[0m\n",
      "\u001b[34m[2022-10-13 01:18:10.539 ip-10-0-179-227.us-west-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Distributed node training with 2 hosts: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] start listen on algo-1:9099\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9099}\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:10:INFO] No data received from connection ('10.0.179.227', 33854). Closing.\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] No data received from connection ('10.0.182.51', 50888). Closing.\u001b[0m\n",
      "\u001b[34m[01:18:13] task NULL got new rank 0\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] Recieve start signal from 10.0.179.227; assign rank 0\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] Recieve start signal from 10.0.182.51; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] @tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] @tracker 0.00164031982421875 secs between node start and job finish\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] start listen on algo-1:9100\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] Rabit slave environment: {'DMLC_TRACKER_URI': 'algo-1', 'DMLC_TRACKER_PORT': 9100}\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:13:INFO] No data received from connection ('10.0.179.227', 46268). Closing.\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:16:INFO] Connected to RabitTracker.\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:16:INFO] No data received from connection ('10.0.182.51', 57762). Closing.\u001b[0m\n",
      "\u001b[34m[01:18:16] task NULL got new rank 0\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:16:INFO] Recieve start signal from 10.0.179.227; assign rank 0\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:16:INFO] Recieve start signal from 10.0.182.51; assign rank 1\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:16:INFO] @tracker All of 2 nodes getting started\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:16:INFO] Train matrix has 1670 rows and 8 columns\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:16:INFO] Validation matrix has 836 rows\u001b[0m\n",
      "\u001b[34m[2022-10-13 01:18:16.861 ip-10-0-179-227.us-west-2.compute.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[01:18:16] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[34m[01:18:16] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:17:INFO] [0]#011train-rmse:8.12719#011validation-rmse:7.97602\u001b[0m\n",
      "\u001b[34m[01:18:17] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:17:INFO] [1]#011train-rmse:6.65223#011validation-rmse:6.50780\u001b[0m\n",
      "\u001b[34m[01:18:17] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:17:INFO] [2]#011train-rmse:5.49551#011validation-rmse:5.36190\u001b[0m\n",
      "\u001b[35m[01:18:16] task NULL got new rank 1\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:16:INFO] Train matrix has 1671 rows and 8 columns\u001b[0m\n",
      "\u001b[35m[2022-10-13:01:18:16:INFO] Validation matrix has 836 rows\u001b[0m\n",
      "\u001b[35m[2022-10-13 01:18:16.861 ip-10-0-182-51.us-west-2.compute.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[01:18:16] INFO: ../src/gbm/gbtree.cc:138: Tree method is automatically selected to be 'approx' for distributed training.\u001b[0m\n",
      "\u001b[35m[01:18:16] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:17] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:17] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:17] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[01:18:17] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:17:INFO] [3]#011train-rmse:4.58920#011validation-rmse:4.47023\u001b[0m\n",
      "\u001b[34m[01:18:18] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:18:INFO] [4]#011train-rmse:3.89878#011validation-rmse:3.80463\u001b[0m\n",
      "\u001b[35m[01:18:18] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:18] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[01:18:18] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:18:INFO] [5]#011train-rmse:3.35980#011validation-rmse:3.28513\u001b[0m\n",
      "\u001b[34m[01:18:18] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [6]#011train-rmse:2.97412#011validation-rmse:2.91678\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 54 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [7]#011train-rmse:2.68460#011validation-rmse:2.63733\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [8]#011train-rmse:2.47254#011validation-rmse:2.44288\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [9]#011train-rmse:2.32436#011validation-rmse:2.32199\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:18] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 54 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [10]#011train-rmse:2.21688#011validation-rmse:2.23463\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [11]#011train-rmse:2.13089#011validation-rmse:2.17340\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [12]#011train-rmse:2.07287#011validation-rmse:2.13373\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:19:INFO] [13]#011train-rmse:2.03545#011validation-rmse:2.10907\u001b[0m\n",
      "\u001b[34m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [14]#011train-rmse:1.99941#011validation-rmse:2.08155\u001b[0m\n",
      "\u001b[34m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [15]#011train-rmse:1.97958#011validation-rmse:2.07329\u001b[0m\n",
      "\u001b[34m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [16]#011train-rmse:1.96386#011validation-rmse:2.06932\u001b[0m\n",
      "\u001b[34m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [17]#011train-rmse:1.94311#011validation-rmse:2.06717\u001b[0m\n",
      "\u001b[34m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [18]#011train-rmse:1.93531#011validation-rmse:2.06582\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:19] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [19]#011train-rmse:1.92105#011validation-rmse:2.06259\u001b[0m\n",
      "\u001b[34m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [20]#011train-rmse:1.90471#011validation-rmse:2.05615\u001b[0m\n",
      "\u001b[34m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:20:INFO] [21]#011train-rmse:1.89159#011validation-rmse:2.05632\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [22]#011train-rmse:1.88125#011validation-rmse:2.05969\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [23]#011train-rmse:1.86743#011validation-rmse:2.05781\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [24]#011train-rmse:1.86058#011validation-rmse:2.05847\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [25]#011train-rmse:1.85536#011validation-rmse:2.05788\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 54 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:20] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [26]#011train-rmse:1.84965#011validation-rmse:2.06448\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [27]#011train-rmse:1.84151#011validation-rmse:2.06263\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [28]#011train-rmse:1.83146#011validation-rmse:2.06486\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [29]#011train-rmse:1.82502#011validation-rmse:2.06838\u001b[0m\n",
      "\u001b[34m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:21:INFO] [30]#011train-rmse:1.81777#011validation-rmse:2.06710\u001b[0m\n",
      "\u001b[34m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:22:INFO] [31]#011train-rmse:1.81223#011validation-rmse:2.07049\u001b[0m\n",
      "\u001b[34m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:22:INFO] [32]#011train-rmse:1.80777#011validation-rmse:2.06975\u001b[0m\n",
      "\u001b[34m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:22:INFO] [33]#011train-rmse:1.80512#011validation-rmse:2.06931\u001b[0m\n",
      "\u001b[34m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:22:INFO] [34]#011train-rmse:1.79639#011validation-rmse:2.07131\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:21] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 38 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:22:INFO] [35]#011train-rmse:1.78394#011validation-rmse:2.07199\u001b[0m\n",
      "\u001b[34m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 34 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:22:INFO] [36]#011train-rmse:1.77380#011validation-rmse:2.06832\u001b[0m\n",
      "\u001b[34m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 52 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:22:INFO] [37]#011train-rmse:1.76408#011validation-rmse:2.07239\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [38]#011train-rmse:1.76003#011validation-rmse:2.07124\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [39]#011train-rmse:1.75385#011validation-rmse:2.07030\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [40]#011train-rmse:1.75132#011validation-rmse:2.07144\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [41]#011train-rmse:1.74562#011validation-rmse:2.07402\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [42]#011train-rmse:1.73922#011validation-rmse:2.07993\u001b[0m\n",
      "\n",
      "2022-10-13 01:18:32 Uploading - Uploading generated training model\u001b[35m[01:18:22] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 52 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 28 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [43]#011train-rmse:1.73699#011validation-rmse:2.08029\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 36 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [44]#011train-rmse:1.72852#011validation-rmse:2.07731\u001b[0m\n",
      "\u001b[34m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:23:INFO] [45]#011train-rmse:1.72292#011validation-rmse:2.07877\u001b[0m\n",
      "\u001b[34m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:24:INFO] [46]#011train-rmse:1.71531#011validation-rmse:2.07916\u001b[0m\n",
      "\u001b[34m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:24:INFO] [47]#011train-rmse:1.70497#011validation-rmse:2.07912\u001b[0m\n",
      "\u001b[34m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:24:INFO] [48]#011train-rmse:1.69710#011validation-rmse:2.07289\u001b[0m\n",
      "\u001b[34m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:24:INFO] [49]#011train-rmse:1.69101#011validation-rmse:2.07618\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:24:INFO] @tracker All nodes finishes job\u001b[0m\n",
      "\u001b[34m[2022-10-13:01:18:24:INFO] @tracker 7.515042543411255 secs between node start and job finish\u001b[0m\n",
      "\u001b[35m[01:18:23] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 30 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 44 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[35m[01:18:24] INFO: ../src/tree/updater_prune.cc:101: tree pruning end, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\n",
      "2022-10-13 01:19:01 Completed - Training job completed\n",
      "Training seconds: 206\n",
      "Billable seconds: 206\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator.fit({'train': train_input, 'validation': validation_input}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "predictor = xgb_estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.    , 0.455 , 0.365 , 0.095 , 0.514 , 0.2245, 0.101 , 0.15  ],\n",
       "       [2.    , 0.35  , 0.265 , 0.09  , 0.2255, 0.0995, 0.0485, 0.07  ],\n",
       "       [0.    , 0.53  , 0.42  , 0.135 , 0.677 , 0.2565, 0.1415, 0.21  ],\n",
       "       [2.    , 0.44  , 0.365 , 0.125 , 0.516 , 0.2155, 0.114 , 0.155 ],\n",
       "       [1.    , 0.33  , 0.255 , 0.08  , 0.205 , 0.0895, 0.0395, 0.055 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = data.iloc[:5, 1:].to_numpy() \n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['9.30324649810791'],\n",
       " ['8.23046588897705'],\n",
       " ['11.059348106384277'],\n",
       " ['9.831652641296387'],\n",
       " ['6.647389888763428']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictor.predict(array)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
